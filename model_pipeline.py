import os
import logging
import json
import mlflow
import mlflow.keras
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from mlflow.models.signature import infer_signature
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
# Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
from logger_config import setup_logging
from data_load import configure_gpu

setup_logging()
logger = logging.getLogger("FullPipeline")

# --- 1. MLflow Custom Wrapper ---
class PlantDiseaseWrapper(mlflow.pyfunc.PythonModel):
    def load_context(self, context):
        self.model = tf.keras.models.load_model(context.artifacts["keras_model"])
        logger.info("âœ… Production Model Loaded into Wrapper.")

    def predict(self, context, model_input):
        return self.model.predict(model_input)

# --- 2. Training Logic (Architecture & Stages) ---
def train_plant_model(train_ds, val_ds, params):
    base_model = tf.keras.applications.ResNet50(
        input_shape=(224, 224, 3), include_top=False, weights='imagenet'
    )
    base_model.trainable = False

    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.BatchNormalization(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.4),
        layers.Dense(38, activation='softmax')
    ])

    metrics = [
        'accuracy',
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall')
    ]

    # Stage 1: Head Training
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=params["lr_stage1"]),
        loss='categorical_crossentropy', metrics=metrics
    )

# Stop training if validation loss stops improving
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    )

    # Dynamically reduce learning rate when the model hits a plateau
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.3,
        patience=4,
        min_lr=1e-6,
        verbose=1
    )

    logger.info("ğŸš€ Stage 1: Training the Head...")
    model.fit(train_ds, validation_data=val_ds, epochs=params["epochs_stage1"], callbacks=[early_stopping, reduce_lr])

    # Stage 2: Fine-Tuning
    logger.info("ğŸ”“ Stage 2: Unfreezing last 50 layers...")
    base_model.trainable = True
    for layer in base_model.layers[:-50]:
        layer.trainable = False

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=params["lr_stage2"]),
        loss='categorical_crossentropy', metrics=metrics
    )
    history = model.fit(train_ds, validation_data=val_ds, epochs=params["epochs_stage2"], 
                        callbacks=[early_stopping, reduce_lr])
    
    return model, history

# --- 3. Full MLOps Lifecycle Orchestrator ---
def run_full_mlops_lifecycle(train_ds, val_ds, test_ds,lr_stage1, lr_stage2, epochs_stage1, epochs_stage2):
    params = {
        "lr_stage1": lr_stage1,
        "lr_stage2":lr_stage2,
        "epochs_stage1": epochs_stage1,
        "epochs_stage2": epochs_stage2,
        "batch_size": 32,
        "quality_gate": 0.80,  # 80% accuracy threshold for production
        "model_name": "PlantModel_Prod"
    }

    configure_gpu()
    mlflow.set_experiment("Plant_Disease_Intelligence")

    with mlflow.start_run(run_name="Professional_Production_Run") as run:
        run_id = run.info.run_id
        mlflow.log_params(params)
        logger.info(f"Started MLflow Run: {run_id}")

        # [A] ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        run_splitting()
        train_ds, val_ds, test_ds, classes = prepare_datasets(
            '/home/youssef/plant_disease_split/train',
            '/home/youssef/plant_disease_split/val',
            '/home/youssef/plant_disease_split/test'
        )
        train_ds = apply_augmentation(train_ds)
        """

        # [B] Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        model, history = train_plant_model(train_ds, val_ds, params)

        """
        # [C] Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
        test_loss, test_acc = model.evaluate(test_ds)
        mlflow.log_metric("test_accuracy", test_acc)
        """
        

        # 1. Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„Ù‡Ø§ ÙÙŠ Ù…ØªØºÙŠØ± ÙˆØ§Ø­Ø¯ (Ù‚Ø§Ø¦Ù…Ø©)
        results = model.evaluate(test_ds)

# 2. ØªÙÙƒÙŠÙƒ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªØ³Ù…ÙŠØªÙ‡Ø§
        test_loss = results[0]
        test_acc = results[1]
        test_precision = results[2]
        test_recall = results[3]

# 3. ØªØ³Ø¬ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ ÙÙŠ MLflow
        mlflow.log_metric("test_accuracy", test_acc)
        mlflow.log_metric("test_precision", test_precision)
        mlflow.log_metric("test_recall", test_recall)

# 4. (Ø¥Ø¶Ø§ÙÙŠ ÙˆÙ…Ù‡Ù… Ø¬Ø¯Ø§Ù‹) Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ F1-Score ÙˆØªØ³Ø¬ÙŠÙ„Ù‡
        f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall + 1e-7)
        mlflow.log_metric("test_f1_score", f1_score)

# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ù€ Terminal Ø¹Ø´Ø§Ù† ØªØªØ§Ø¨Ø¹Ù‡Ø§
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Precision: {test_precision:.4f}")
        print(f"Test Recall: {test_recall:.4f}")
        print(f"Test F1-Score: {f1_score:.4f}")

        # Ø±Ø³Ù… Ø§Ù„Ù€ Precision ÙˆØ§Ù„Ù€ Recall Ù„Ù„Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù€ MLflow
        plt.figure(figsize=(10, 5))
        plt.plot(history.history['precision'], label='train_precision')
        plt.plot(history.history['val_precision'], label='val_precision')
        plt.title('Precision Evolution')
        plt.savefig("precision_report.png")
        mlflow.log_artifact("precision_report.png")


        plt.figure(figsize=(10, 5))
        plt.plot(history.history['accuracy'], label='train_acc')
        plt.plot(history.history['val_accuracy'], label='val_acc')
        plt.title('Accuracy Evolution')
        plt.savefig("accuracy_report.png")
        mlflow.log_artifact("accuracy_report.png")

        # [D] Ø§Ù„ØªØºÙ„ÙŠÙ (Packaging)
        sample_img = next(iter(test_ds))[0][:1].numpy()
        signature = infer_signature(sample_img, model.predict(sample_img))
        model_temp_path = "final_plant_model.keras"
        model.save(model_temp_path)
        
        mlflow.pyfunc.log_model(
            artifact_path="plant_disease_model",
            python_model=PlantDiseaseWrapper(),
            artifacts={"keras_model": model_temp_path},
            signature=signature
        )

        # --- 4. Ø§Ù„Ù€ Registry Workflow Ø§Ù„Ù„ÙŠ Ø·Ù„Ø¨ØªÙ‡ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ ---
        
        client = mlflow.tracking.MlflowClient()
        model_uri = f"runs:/{run_id}/plant_disease_model"
        model_name = params["model_name"]

        # 1. Registration
        logger.info(f"ğŸ“¦ Step 1: Registering model '{model_name}'...")
        model_details = mlflow.register_model(model_uri, model_name)
        version = model_details.version

        # 2. Transition to Staging
        logger.info(f"ğŸ§ª Step 2: Transitioning version {version} to STAGING...")
        client.transition_model_version_stage(
            name=model_name, version=version, stage="Staging"
        )

        # 3. Quality Gate
        logger.info(f"âš–ï¸ Step 3: Checking Quality Gate (Target: {params['quality_gate']*100}%)...")
        
        if test_acc >= params["quality_gate"] and f1_score >= 0.80:
            # 4. Transition to Production
            logger.info(f"âœ… Quality Gate Passed! (Accuracy: {test_acc:.4f})")
            logger.info(f"ğŸš€ Step 4: Promoting version {version} to PRODUCTION...")
            
            client.transition_model_version_stage(
                name=model_name,
                version=version,
                stage="Production",
                archive_existing_versions=True
            )
            logger.info(f"ğŸŒŸ Model version {version} is now LIVE in Production.")
        else:
            logger.warning(f"âš ï¸ Quality Gate Failed (Accuracy: {test_acc:.4f}).")
            logger.warning(f"ğŸ›‘ Model version {version} will remain in STAGING for review.")
        return run_id

if __name__ == "__main__":
    run_full_mlops_lifecycle()